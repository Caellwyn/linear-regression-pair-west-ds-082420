{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "import pandas as pd\n", "import numpy as np\n", "\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "from scipy import stats\n", "import statsmodels.api as sm\n", "from statsmodels.formula.api import ols"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For this exercise we will work through the different steps of a linear regression workflow. The notebook will walk you through building a first simple model and improving upon that model by stepwise iteration.\n", "\n", "### 1. First Simple Model\n", "- Load in the dataset: inspect the overall shape, duplicate entries, and NA's.\n", "- Identify the continuous target variable\n", "- Perform initial EDA: correlation plots\n", "- Build a FSM (First Simple Model) with statsmodels\n", "- Interpret coefficients\n", "- Check the assumptions of linear regression  \n", "\n", "### 2. Iterate: Build a better model - Add another numerical feature\n", "- Add another feature, and fit the model\n", "- Compare metrics and interpret coefficients\n", "- Check the assumptions\n", "\n", "### 3. Iterate: Build a better model - Add a categorical feature\n", "- Add a categorical variable \n", "- Compare metrics and interpret coefficients\n", "- Check the assumptions once-again\n", "\n", "### 4. Conclusion\n", "- Pick your best model, and interpret your findings\n", "- Describe the next steps you would take if you had more time"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## The Dataset\n", "We will use a dataset from [Kaggle](https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho). It contains information about **used car sale listings**. We are trying to understand the relationships between the various features of the listing and the **price of the car**.\n", "\n", "### Features (as described on Kaggle)\n", " - `Car_Name`: The name of the car\n", " - `Year`: The year in which the car was bought\n", " - `Selling_Price`: The price the owner wants to sell the car at\n", " - `Present_Price`: The current ex-showroom price of the car\n", " - `Kms_Driven`: The distance completed by the car in km\n", " - `Fuel_Type`: The fuel type of the car (Petrol, Diesel, or Other)\n", " - `Seller_Type`: Whether the seller is a dealer or an individual\n", " - `Transmission`: Whether the car is manual or automatic\n", " - `Owner`: The number of owners the car has previously had\n", "\n", "Looking at the original website, it looks like the **prices are listed in lakhs, meaning hundreds of thousands of rupees**.\n", "\n", "The datasets is located in a file called `cars.csv` in the `data` directory."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. FSM"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Load in the dataset and check the overall shape\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# load in the dataset\n", "df = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# How many records and columns are in the data set?\n", "records, columns = None\n", "\n", "print(records, \"records\")\n", "print(columns, \"columns\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Check for duplicate entries\n", "# Your answer here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Check for na's (just look to get an idea; don't drop or impute yet)\n", "# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### What does a row in the dataframe represent?\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Identify the continous target variable"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# To make things easier to interpet, set the target to column index 0\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Understanding the Target Variable"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Revisit the continuous target variable.  \n", "# Explore it a bit.  Plot a histogram of its distribution as well as a boxplot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# What are the 10 most expensive listings?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Describe the distribution of the target"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Perform Initial EDA\n", "\n", "Let's look at a correlation matrix to see which of these variables might be the most useful.  (Here we are looking for variables that are highly correlated with the target variable, but not highly correlated with other input variables.) This only includes the numeric values."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# create a correlation matrix\n", "# first, just use the dataframe .corr() method to output a numerical matrix\n", "\n", "# Your answer here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Then pass the above code into Seaborn's heatmap plot\n", "\n", "# Your answer here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Try adding the code in this cell to the mask attribute in the heatmap to halve the plot\n", "mask = np.triu(np.ones_like(df.corr(), dtype=np.bool))\n", "\n", "# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Use seaborn's pairplot function on the features above\n", "\n", "There are only 5 numeric features, so this shouldn't be _too_ slow"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Judging from this pairplot (either the top row, or the left column), the closest to a linear relationship is `Present_Price`. This also happens to be the feature with the highest correlation to `Selling_Price`.\n", "\n", "This makes sense, that the original price of the car, and the listed price for that car when it's used, would be highly correlated.\n", "\n", "Given these insights, let's use `Present_Price` to develop the First Simple Model (FSM), with one target and one predictor."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## FSM with Statsmodels\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create a dataframe with only the target and the chosen\n", "# high-positive correlation feature\n", "fsm_df = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Build the R-style formula.\n", "# The format is \"target ~ feature_1 + feature_2 + feature_3\"\n", "formula = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Fit the model on the dataframe composed of the two features\n", "fsm = ols(formula=formula, data=fsm_df).fit()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Use the summary() method on the fsm variable to print out the results of the fit.\n", "fsm.summary()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# The object also has attributes associated with the ouput, such as: rsquared, and params.\n", "# save those values to the variables below.\n", "\n", "rsquared = None\n", "params = None\n", "\n", "print(f'Rsquared of FSM: {rsquared}')\n", "print('----------')\n", "print('Beta values of FSM:')\n", "print(params)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Interpret the result of the FSM.  What does the R Squared tell you? Remember the formula for:\n", "\n", "$\\Large R^2 = 1 - \\frac{SSE}{SST}$\n", "\n", "Also, interepret the coefficients.  If we increase the value of our independent variable by 1, what does it mean for our predicted value?\n", "\n", "What will our model predict the value of sale price to be for a car originally worth 0 lakhs? (This doesn't necessarily make sense.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Check the assumptions of Linear Regression"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 1. Linearity\n", "\n", "Linear regression assumes that the input variable linearly predicts the output variable.  We already qualitatively checked that with a scatter plot.  But it's also a good idea to use a statistical test.  This one is the [Rainbow test](https://www.tandfonline.com/doi/abs/10.1080/03610928208828423) which is available from the [diagnostic submodule of StatsModels](https://www.statsmodels.org/stable/generated/statsmodels.stats.diagnostic.linear_rainbow.html#statsmodels.stats.diagnostic.linear_rainbow)\n", "\n", "1a) What are the null and alternative hypotheses for the linear rainbow test?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["1b) Run a statistical test for linearity (we've included the import below)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from statsmodels.stats.diagnostic import linear_rainbow\n", "\n", "# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["1c) Interpret the results. Can we reject the null hypothesis? (You can assume an alpha of 0.05.) What does this mean for the assumptions of linear regression?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 2. Normality\n", "\n", "Linear regression assumes that the residuals are normally distributed.  It is possible to check this qualitatively with a Q-Q plot.  The fit model object has an attribute called `resid`, which is an array of the difference between predicted and true values.  Store the residuals in the variable below, show the qq plot, and interepret. You are looking for the theoretical quantiles and the sample quantiles to line up."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create a qq-plot\n", "\n", "fsm_resids = None\n", "\n", "sm.qqplot(fsm_resids);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Those qqplots don't look so good in the upper right corner. To pass a visual test, the qq should be a straight line."]}, {"cell_type": "markdown", "metadata": {}, "source": ["The [Jarque-Bera](https://en.wikipedia.org/wiki/Jarque%E2%80%93Bera_test) test is performed automatically as part of the model summary output, labeled **Jarque-Bera (JB)** and **Prob(JB)**.\n", "\n", "The null hypothesis is that the residuals are normally distributed, alternative hypothesis is that they are not.  \n", "What does the JB score output indicate. Does it support the qq-plot?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 3. Homoscadasticity\n", "\n", "Linear regression assumes that the variance of the dependent variable is homogeneous across different values of the independent variable(s).  We can visualize this by looking at the predicted life expectancy vs. the residuals.\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Use the predict() method now available to be called from the fsm variable \n", "# to store the predictions\n", "y_hat = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# plot y_hat against the residuals (stored in fsm_resids) in a scatter plot\n", "\n", "# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Interepret the result. Do you see any patterns that suggest that the residuals exhibit heteroscedasticity?\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's also run a statistical test.  The [Breusch-Pagan test](https://en.wikipedia.org/wiki/Breusch%E2%80%93Pagan_test) is available from the [diagnostic submodule of StatsModels](https://www.statsmodels.org/stable/generated/statsmodels.stats.diagnostic.het_breuschpagan.html#statsmodels.stats.diagnostic.het_breuschpagan)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from statsmodels.stats.diagnostic import het_breuschpagan\n", "lm, lm_p_value, fvalue, f_p_value = het_breuschpagan(fsm_resids, fsm_df[[\"Present_Price\"]])\n", "print(\"Lagrange Multiplier p-value:\", lm_p_value)\n", "print(\"F-statistic p-value:\", f_p_value)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The null hypothesis is homoscedasticity, alternative hypothesis is heteroscedasticity.  \n", "What does the p-value returned above indicate? Can you reject the null hypothesis?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 4. Independence\n", "\n", "The independence assumption means that the independent variables must not be too collinear.  Right now we have only one independent variable, so we don't need to check this yet."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Train a model with `sklearn`\n", "The `sklearn` interface is simpler than StatsModels, but it does not give us the super helpful StatsModels output.  We will, however, use its syntax consistently with other algorithms.\n", "\n", "You can skip this step if you are short on time, since it is more relevant for Phase 3 than Phase 2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LinearRegression\n", "\n", "# instantiate a linear regression object \n", "lr = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# split the data into target and features\n", "y = None\n", "X = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Call .fit from the linear regression object, and feed X and y in as parameters\n", "# Your code here"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# lr has a method called score.  Again, feed in X and y, and read the output. \n", "# Save it in the variable score. What is that number?  Compare it to statsmodels. \n", "score = None\n", "score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# lr also has attributes coef_ and intercept_. Save and compare to statsmodels\n", "beta = None\n", "intercept = None\n", "\n", "print(beta)\n", "print(intercept)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Iterate: Build a better model - Add another numerical feature"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Adding Features to the Model\n", "\n", "So far, all we have is a simple linear regression.  Let's start adding features to make it a multiple regression.\n", "\n", "Let's try `Year`. Maybe in reality it should be a categorical variable, but it looks like there's a general trend where the later the year, the higher the price"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize=(10, 5))\n", "\n", "sns.catplot(x=\"Year\", y=\"Selling_Price\", data=df, ax=ax, kind=\"box\")\n", "plt.close(2); # closing the extra axis created by sns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create another dataframe containing our three features of interest\n", "model_2_df = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# save the R-like formula into the variable\n", "formula = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# train the model like we did above\n", "model_2 = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# print out the summary table\n", "# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Did the r_2 improve? "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Now check the assumptions like we did above.\n", "\n", "#### Linearity"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here (code and interpretation)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Normality"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here (interpretation of output from model summary)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Homoscedasticity"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here (code and interpretation)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Independence\n", "\n", "You might have noticed in the regression output that there was a warning about the condition number being high. The condition number is a measure of stability of the matrix used for computing the regression (we'll discuss this more in the next module), and a number above 30 can indicate strong multicollinearity. Our output is way higher than that.\n", "\n", "A different (more generous) measure of multicollinearity is the variance inflation factor. It is available from the outlier influence submodule of StatsModels.\n", "\n", "Run the code below:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from statsmodels.stats.outliers_influence import variance_inflation_factor\n", "rows = model_2_df[[\"Present_Price\", \"Year\"]].values\n", "\n", "vif_df = pd.DataFrame()\n", "vif_df[\"VIF\"] = [variance_inflation_factor(rows, i) for i in range(2)]\n", "vif_df[\"feature\"] = [\"Present_Price\", \"Year\"]\n", "\n", "vif_df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A \"rule of thumb\" for VIF is that 5 is too high.  Given the output above, it's reasonable to say that we are not violating the independence assumption, despite the high condition number."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Iterate: Build a better model - Add a categorical feature\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Rather than adding any more numeric features (e.g. `Year`, `Owner`), let's add a categorical one. Out of `Seller_Type` and `Transmission`, which one looks better?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 8))\n", "\n", "sns.catplot(y=\"Selling_Price\", x=\"Seller_Type\", data=df, ax=ax1, kind=\"box\")\n", "plt.close(2)\n", "sns.catplot(y=\"Selling_Price\", x=\"Transmission\", data=df, ax=ax2, kind=\"box\")\n", "plt.close(2);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["It looks like `Seller Type` has more separation between the two classes, let's go with that"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[\"Seller_Type\"].value_counts()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# We have created a dataframe with the necessary columns\n", "model_3_df = df[[\"Selling_Price\", \"Present_Price\", \"Year\", \"Seller_Type\"]].copy()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["There are only two categories, so we only need a `LabelEncoder` that will convert the labels into 1s and 0s.  If there were more than two categories, we would use a `OneHotEncoder`, which would create multiple columns out of a single column."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import LabelEncoder\n", "\n", "# instantiate an instance of LabelEncoder\n", "label_encoder = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Pass the \"Seller_Type\" column of the model_3_df to the fit_transform() \n", "# method of the Label Encoder\n", "seller_labels = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run the code below.  The category Dealer/Individual has been transformed to a binary\n", "np.unique(seller_labels, return_counts=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run the code below to see the classes associated with 1 and 0\n", "label_encoder.classes_"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This is telling us that \"Dealer\" is encoded as 0 and \"Individual\" is encoded as 1.  This means that \"Dealer\" is assumed at the intercept."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Add the seller labels array to the model_df as a column \n", "model_3_df[\"Seller_Encoded\"] = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Drop the Seller_Type column\n", "\n", "# your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Fit the 3rd Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# assign the new formula\n", "\n", "formula=None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# fit the new model\n", "model_3 = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# print the summary\n", "model_3.summary()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Third Model Evaluation\n", "\n", "Did the R_squared improve?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Let's look at the model assumptions again"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Linearity, Normality, Homoscedasticity, Independence\n", "\n", "For each, are we violating the assumption? Have we improved from the previous model?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Conclusion\n", "\n", "Choose a model out of `fsm`, `model_2`, and `model_3` and declare it as your final model. How well does this model represent the target variable?  What can we say about car listing prices based on these variables?  What coefficients, if any, are statistically significant?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.3"}}, "nbformat": 4, "nbformat_minor": 4}